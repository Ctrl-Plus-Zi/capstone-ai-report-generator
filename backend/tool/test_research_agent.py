"""
ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ê¸°ê´€ëª…ê³¼ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ë§Œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
API í˜¸ì¶œ ê³¼ì •ë„ ìƒì„¸íˆ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    print("âš ï¸  tiktokenì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í† í° ìˆ˜ ê³„ì‚°ì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¤ì¹˜: pip install tiktoken")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool
from typing import Annotated
from app.agents.search_agent import create_search_agent
from app.agents.agent_state import ReportingAgentState
from app.agents.graph_util import ReportingTools
from app.config import settings

# ì „ì—­ ë³€ìˆ˜: DESCRIPTION í¬í•¨ ì—¬ë¶€
include_description = False

# í† í° ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def count_tokens(text: str, model: str = "gpt-4o") -> int:
    """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if not TIKTOKEN_AVAILABLE:
        # ëŒ€ëµì ì¸ ì¶”ì •: ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ìˆ˜ë¥¼ ì„¸ê³  1.3ì„ ê³±í•¨ (í•œêµ­ì–´ëŠ” ë” ë³µì¡í•˜ì§€ë§Œ ê·¼ì‚¬ì¹˜)
        return int(len(text.split()) * 1.3)
    
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except:
        # ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ cl100k_base ì¸ì½”ë”© ì‚¬ìš© (gpt-4, gpt-3.5-turbo ë“±)
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))

# API í˜¸ì¶œì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë˜í¼ í•¨ìˆ˜
from app.agents.api_utils import call_kcisa_api, call_kma_asos_daily_api

_original_call_kcisa_api = call_kcisa_api
_original_call_kma_asos_daily_api = call_kma_asos_daily_api

def _debug_call_kcisa_api(*args, **kwargs):
    """API í˜¸ì¶œì„ ì¶”ì í•˜ëŠ” ë˜í¼"""
    api_name = kwargs.get('api_name') or (args[0] if args else 'N/A')
    keyword = kwargs.get('keyword')
    filter_value = kwargs.get('filter_value')
    num_of_rows = kwargs.get('num_of_rows', 50)
    page_no = kwargs.get('page_no', 1)
    
    print("\n" + "="*80)
    print(f"ğŸŒ [API í˜¸ì¶œ ì‹œì‘] {api_name}")
    print("-" * 80)
    print(f"   íŒŒë¼ë¯¸í„°:")
    print(f"     - keyword: {keyword}")
    print(f"     - filter_value: {filter_value}")
    print(f"     - num_of_rows: {num_of_rows}")
    print(f"     - page_no: {page_no}")
    print("="*80)
    
    result = _original_call_kcisa_api(*args, **kwargs)
    
    print(f"\nğŸ“¡ [API í˜¸ì¶œ ê²°ê³¼] {api_name}")
    print("-" * 80)
    if result.get('url'):
        print(f"   í˜¸ì¶œ URL: {result['url']}")
    print(f"   ì„±ê³µ ì—¬ë¶€: {result.get('success', False)}")
    if result.get('success'):
        print(f"   ë°ì´í„° ê°œìˆ˜: {result.get('count', 0)}")
        print(f"   API ì„¤ëª…: {result.get('api_description', 'N/A')}")
    else:
        print(f"   ì˜¤ë¥˜: {result.get('error', 'N/A')}")
    print("="*80 + "\n")
    
    return result

def _debug_call_kma_asos_daily_api(*args, **kwargs):
    """ê¸°ìƒì²­ API í˜¸ì¶œì„ ì¶”ì í•˜ëŠ” ë˜í¼"""
    start_dt = kwargs.get('start_dt') or (args[0] if args else 'N/A')
    end_dt = kwargs.get('end_dt') or (args[1] if len(args) > 1 else 'N/A')
    stn_ids = kwargs.get('stn_ids', '108')
    num_of_rows = kwargs.get('num_of_rows', 999)
    
    print("\n" + "="*80)
    print("ğŸŒ [API í˜¸ì¶œ ì‹œì‘] KMA_ASOS_DAILY (ê¸°ìƒì²­ ì¼ìë£Œ)")
    print("-" * 80)
    print(f"   íŒŒë¼ë¯¸í„°:")
    print(f"     - start_dt: {start_dt}")
    print(f"     - end_dt: {end_dt}")
    print(f"     - stn_ids: {stn_ids}")
    print(f"     - num_of_rows: {num_of_rows}")
    print("="*80)
    
    result = _original_call_kma_asos_daily_api(*args, **kwargs)
    
    print(f"\nğŸ“¡ [API í˜¸ì¶œ ê²°ê³¼] KMA_ASOS_DAILY")
    print("-" * 80)
    print(f"   ì„±ê³µ ì—¬ë¶€: {result.get('success', False)}")
    if result.get('success'):
        print(f"   ë°ì´í„° ê°œìˆ˜: {result.get('count', 0)}")
        print(f"   API ì„¤ëª…: {result.get('api_description', 'N/A')}")
        if result.get('result_code'):
            print(f"   ê²°ê³¼ ì½”ë“œ: {result.get('result_code')}")
            print(f"   ê²°ê³¼ ë©”ì‹œì§€: {result.get('result_msg', 'N/A')}")
    else:
        print(f"   ì˜¤ë¥˜: {result.get('error', 'N/A')}")
    print("="*80 + "\n")
    
    return result

# Monkey patchìœ¼ë¡œ API í˜¸ì¶œ í•¨ìˆ˜ êµì²´
import app.agents.api_utils as api_utils_module
api_utils_module.call_kcisa_api = _debug_call_kcisa_api
api_utils_module.call_kma_asos_daily_api = _debug_call_kma_asos_daily_api


# API í˜¸ì¶œì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤
class DebugReportingTools(ReportingTools):
    """API í˜¸ì¶œì„ ì¶”ì í•˜ëŠ” ReportingTools ë˜í¼"""
    
    @staticmethod
    @tool
    def search_exhibition_info_api(
        keyword: Annotated[str, "ì „ì‹œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: www.museum.go.kr)"] = "www.museum.go.kr",
        num_of_rows: Annotated[int, "ì¡°íšŒí•  ë°ì´í„° í–‰ ìˆ˜"] = 50
    ):
        """í•œêµ­ë¬¸í™”ì •ë³´ì› ì „ì‹œì •ë³´ í†µí•© API (KCISA_CCA_145)ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë¬¸í™”ì‹œì„¤ì˜ ì „ì‹œ ì •ë³´, ì´ë²¤íŠ¸, í”„ë¡œê·¸ë¨ ë“±ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] search_exhibition_info_api")
        print(f"   í‚¤ì›Œë“œ: {keyword}")
        print(f"   í–‰ ìˆ˜: {num_of_rows}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        from app.agents.api_utils import call_kcisa_api
        # ì „ì—­ ë³€ìˆ˜ì—ì„œ include_description ê°€ì ¸ì˜¤ê¸°
        global include_description
        # keywordê°€ URL íŒ¨í„´ì¸ ê²½ìš° ê¸°ê´€ëª…ìœ¼ë¡œ ë³€í™˜ ì‹œë„
        filter_value = None
        if keyword and ("www." in keyword or ".go.kr" in keyword or ".kr" in keyword):
            # URL íŒ¨í„´ì¸ ê²½ìš°, filter_valueë¡œë§Œ ì‚¬ìš© (ì„œë²„ ì‚¬ì´ë“œ ê²€ìƒ‰ì€ í•˜ì§€ ì•ŠìŒ)
            filter_value = keyword
            keyword = None
        # ê¸°ê´€ëª…ì¸ ê²½ìš° keywordë¡œë§Œ ì„œë²„ ì‚¬ì´ë“œ ê²€ìƒ‰ ì‚¬ìš© (filter_valueëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        # ì„œë²„ ì‚¬ì´ë“œ ê²€ìƒ‰ì´ ì´ë¯¸ ê¸°ê´€ëª…ìœ¼ë¡œ í•„í„°ë§í•˜ë¯€ë¡œ ì¤‘ë³µ í•„í„°ë§ ë¶ˆí•„ìš”
        
        api_result = call_kcisa_api(
            api_name="KCISA_CCA_145",
            keyword=keyword,  # ì„œë²„ ì‚¬ì´ë“œ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° (ê¸°ê´€ëª…ì¸ ê²½ìš°ë§Œ)
            filter_value=filter_value,  # í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ í•„í„°ë§ (URLì¸ ê²½ìš°ë§Œ)
            num_of_rows=num_of_rows,
            filter_remove_fields=not include_description
        )
        
        if api_result["success"]:
            result = {
                "notes": f"{api_result['api_description']} ê²€ìƒ‰ ì™„ë£Œ: ì´ {api_result['count']}ê°œì˜ ì „ì‹œ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
                "sources": [item.get("URL") for item in api_result["data"] if item.get("URL")],
                "data": api_result["data"]
            }
        else:
            result = {
                "notes": f"ì „ì‹œ ì •ë³´ ê²€ìƒ‰ ì‹¤íŒ¨: {api_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                "sources": [],
                "data": []
            }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print(f"   ë°˜í™˜ëœ ë°ì´í„° ê°œìˆ˜: {len(result.get('data', []))}")
        if result.get('data'):
            print(f"   ìƒ˜í”Œ ë°ì´í„° (ì²« 1ê°œ):")
            print(json.dumps(result['data'][0], ensure_ascii=False, indent=4))
        print("="*80 + "\n")
        return result
    
    @staticmethod
    @tool
    def search_museum_collection_api(
        keyword: Annotated[str, "ì†Œì¥í’ˆì„ ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: ì²­ì, í˜¸ë‘ì´, ë¶ˆìƒ ë“±)"] = "ì²­ì",
        num_of_rows: Annotated[int, "ì¡°íšŒí•  ë°ì´í„° í–‰ ìˆ˜"] = 50
    ):
        """êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ ì†Œì¥í’ˆ ê²€ìƒ‰ API (KCISA_CPM_003)ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë°•ë¬¼ê´€ ì†Œì¥í’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] search_museum_collection_api")
        print(f"   í‚¤ì›Œë“œ: {keyword}")
        print(f"   í–‰ ìˆ˜: {num_of_rows}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        from app.agents.api_utils import call_kcisa_api
        api_result = call_kcisa_api(
            api_name="KCISA_CPM_003",
            filter_value=keyword,
            num_of_rows=num_of_rows
        )
        
        if api_result["success"]:
            result = {
                "notes": f"{api_result['api_description']} ê²€ìƒ‰ ì™„ë£Œ: ì´ {api_result['count']}ê°œì˜ ì†Œì¥í’ˆ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
                "sources": [item.get("url") for item in api_result["data"] if item.get("url")],
                "data": api_result["data"]
            }
        else:
            result = {
                "notes": f"ì†Œì¥í’ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {api_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                "sources": [],
                "data": []
            }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print(f"   ë°˜í™˜ëœ ë°ì´í„° ê°œìˆ˜: {len(result.get('data', []))}")
        if result.get('data'):
            print(f"   ìƒ˜í”Œ ë°ì´í„° (ì²« 1ê°œ):")
            print(json.dumps(result['data'][0], ensure_ascii=False, indent=4))
        print("="*80 + "\n")
        return result
    
    @staticmethod
    @tool
    def search_performance_info_api(
        keyword: Annotated[str, "ê³µì—° ì •ë³´ë¥¼ ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: ì˜ˆìˆ ì˜ì „ë‹¹, ì—°ê·¹, ì½˜ì„œíŠ¸ ë“±)"] = "ì˜ˆìˆ ì˜ì „ë‹¹",
        num_of_rows: Annotated[int, "ì¡°íšŒí•  ë°ì´í„° í–‰ ìˆ˜"] = 50
    ):
        """í•œêµ­ë¬¸í™”ì •ë³´ì› ê³µì—°ì •ë³´ í†µí•© API(KCISA_CCA_144)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] search_performance_info_api")
        print(f"   í‚¤ì›Œë“œ: {keyword}")
        # ì˜ˆìˆ ì˜ì „ë‹¹ì¸ ê²½ìš° 10ê°œë¡œ ì œí•œ
        if "ì˜ˆìˆ ì˜ì „ë‹¹" in keyword or "ì˜ˆìˆ ì˜ ì „ë‹¹" in keyword:
            num_of_rows = min(num_of_rows, 10)
            print(f"   í–‰ ìˆ˜: {num_of_rows} (ì˜ˆìˆ ì˜ì „ë‹¹ì´ë¯€ë¡œ ìµœëŒ€ 10ê°œë¡œ ì œí•œ)")
        else:
            print(f"   í–‰ ìˆ˜: {num_of_rows}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        from app.agents.api_utils import call_kcisa_api
        # ì „ì—­ ë³€ìˆ˜ì—ì„œ include_description ê°€ì ¸ì˜¤ê¸°
        global include_description
        api_result = call_kcisa_api(
            api_name="KCISA_CCA_144",
            keyword=keyword,
            num_of_rows=num_of_rows,
            filter_remove_fields=not include_description
        )
        
        if api_result.get("success"):
            data = api_result.get("data", [])
            def pick_source(it: dict):
                return it.get("URL") or it.get("IMAGE_OBJECT") or it.get("LOCAL_ID")
            sources = [pick_source(it) for it in data if pick_source(it)]
            result = {
                "notes": f"{api_result.get('api_description','ê³µì—°ì •ë³´')} ê²€ìƒ‰ ì™„ë£Œ: ì´ {api_result.get('count', 0)}ê°œì˜ ê³µì—° ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
                "sources": sources,
                "data": data
            }
        else:
            result = {
                "notes": f"ê³µì—° ì •ë³´ ê²€ìƒ‰ ì‹¤íŒ¨: {api_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                "sources": [],
                "data": []
            }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print(f"   ë°˜í™˜ëœ ë°ì´í„° ê°œìˆ˜: {len(result.get('data', []))}")
        if result.get('data'):
            print(f"   ìƒ˜í”Œ ë°ì´í„° (ì²« 1ê°œ):")
            print(json.dumps(result['data'][0], ensure_ascii=False, indent=4))
        print("="*80 + "\n")
        return result
    
    @staticmethod
    @tool
    def search_weather_daily_api(
        year: Annotated[int, "ì—°ë„"] = 2025,
        month: Annotated[int, "ì›”(1~12)"] = 1,
        stn_ids: Annotated[str, "ì§€ì ì½”ë“œ(ì˜ˆ: 108=ì„œìš¸)"] = "108",
        num_of_rows: Annotated[int, "í–‰ ìˆ˜"] = 999,
    ):
        """KMA ASOS ì¼ìë£Œ(ì¼ë³„)ë¥¼ ì›” ë‹¨ìœ„ë¡œ ì¡°íšŒí•˜ëŠ” íˆ´. tm/sumRn/maxTa/minTa í•„ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] search_weather_daily_api")
        print(f"   ì—°ë„: {year}")
        print(f"   ì›”: {month}")
        print(f"   ì§€ì ì½”ë“œ: {stn_ids}")
        print(f"   í–‰ ìˆ˜: {num_of_rows}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        from app.agents.api_utils import call_kma_asos_daily_api, month_range
        try:
            start_dt, end_dt = month_range(year, month)
        except ValueError as e:
            result = {"notes": f"ì…ë ¥ ì˜¤ë¥˜: {e}", "sources": [], "data": []}
        else:
            api_result = call_kma_asos_daily_api(start_dt, end_dt, stn_ids, num_of_rows)
            if api_result["success"]:
                result = {
                    "notes": f"{api_result['api_description']} {year}ë…„ {month}ì›” ì¡°íšŒ ì™„ë£Œ: ì´ {api_result['count']}ê°œì˜ ì¼ìë£Œ.",
                    "sources": [],
                    "data": api_result["data"]
                }
            else:
                result = {
                    "notes": f"ë‚ ì”¨ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {api_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                    "sources": [],
                    "data": []
                }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print(f"   ë°˜í™˜ëœ ë°ì´í„° ê°œìˆ˜: {len(result.get('data', []))}")
        if result.get('data'):
            print(f"   ìƒ˜í”Œ ë°ì´í„° (ì²« 1ê°œ):")
            print(json.dumps(result['data'][0], ensure_ascii=False, indent=4))
        print("="*80 + "\n")
        return result
    
    @staticmethod
    @tool
    def search_internal_documents(
        query: Annotated[str, "ê²€ìƒ‰í•  ë‚´ë¶€ ë°ì´í„°ì— ëŒ€í•œ ì§ˆë¬¸."],
        limit: Annotated[int, "Maximum number of items to retrieve."] = 5
    ):
        """ë‚´ë¶€ ì§€ì‹ ê¸°ë°˜ì—ì„œ ë³´ê³ ì„œì— ê´€ë ¨ëœ ìë£Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì½”ë“œ êµ¬í˜„ ì˜ˆì •"""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] search_internal_documents")
        print(f"   ì¿¼ë¦¬: {query}")
        print(f"   ì œí•œ: {limit}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        result = {
            "notes": "ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "sources": []
        }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print("="*80 + "\n")
        return result
    
    @staticmethod
    @tool
    def fetch_data_snapshot(
        dataset: Annotated[str, "ê°€ì ¸ì˜¬ ë°ì´í„°ì…‹ì˜ ì‹ë³„ì."],
        window: Annotated[str, "Desired time range for the snapshot."] = "latest"
    ):
        """êµ¬ì¡°í™”ëœ ë°ì´í„° ìŠ¤ëƒ…ìƒ·ì„ ê°€ì ¸ì™€ í›„ì† ë¶„ì„ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì½”ë“œ êµ¬í˜„ ì˜ˆì •"""
        print("\n" + "="*80)
        print("ğŸ” [ë„êµ¬ í˜¸ì¶œ] fetch_data_snapshot")
        print(f"   ë°ì´í„°ì…‹: {dataset}")
        print(f"   ìœˆë„ìš°: {window}")
        print("="*80)
        # ì›ë³¸ í•¨ìˆ˜ì˜ ì‹¤ì œ êµ¬í˜„ì„ ì§ì ‘ í˜¸ì¶œ (ì½œë°± ì¶©ëŒ ë°©ì§€)
        result = {
            "notes": "ë°ì´í„° ìŠ¤ëƒ…ìƒ· ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "sources": []
        }
        print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {result.get('notes', 'N/A')}")
        print("="*80 + "\n")
        return result


def main():
    print("\n" + "="*80)
    print("ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸")
    print("="*80 + "\n")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not settings.openai_api_key:
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    organization_name = input("ê¸°ê´€ëª…>> ").strip()
    if not organization_name:
        print("âŒ ê¸°ê´€ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    question = input("ì§ˆë¬¸>> ").strip()
    if not question:
        print("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    # DESCRIPTION í•­ìƒ í¬í•¨
    global include_description
    include_description = True
    
    # ì˜¤ëŠ˜ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    today = datetime.now()
    current_date = today.strftime("%Y-%m-%d")
    current_year = today.year
    current_month = today.month
    
    print(f"\nğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {current_date} (ìë™ìœ¼ë¡œ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê³µì—°/ì „ì‹œë§Œ í•„í„°ë§ë©ë‹ˆë‹¤)")
    
    print("\n" + "="*80)
    print("ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
    print("="*80 + "\n")
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model=settings.llm_model,
        temperature=settings.llm_temperature,
        api_key=settings.openai_api_key,
    )
    
    # ë””ë²„ê¹…ìš© íˆ´í‚· ì´ˆê¸°í™”
    toolkit = DebugReportingTools()
    
    # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ìƒì„±
    search_agent = create_search_agent(llm, toolkit)
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì • (ì˜¤ëŠ˜ ë‚ ì§œ í¬í•¨)
    initial_state: ReportingAgentState = {
        "request_context": {
            "organization_name": organization_name,
            "report_topic": question,
            "questions": [question],
            "current_date": current_date,  # ì˜¤ëŠ˜ ë‚ ì§œ ì¶”ê°€
            "current_year": current_year,
            "current_month": current_month,
            "filter_active_only": True,  # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê²ƒë§Œ í•„í„°ë§ í”Œë˜ê·¸
        },
        "messages": [HumanMessage(content=f"{question} (ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}, í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê³µì—°/ì „ì‹œë§Œ í¬í•¨í•´ì£¼ì„¸ìš”)")],
        "research_notes": "",
        "research_sources": [],
        "research_payload": [],
    }
    
    print("\n" + "="*80)
    print("ğŸ“‹ ìš”ì²­ ì»¨í…ìŠ¤íŠ¸")
    print("="*80)
    print(json.dumps(initial_state["request_context"], ensure_ascii=False, indent=2))
    print("="*80 + "\n")
    
    # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì‹¤í–‰
    try:
        result_state = search_agent(initial_state)
        
        print("\n" + "="*80)
        print("ğŸ“Š ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼")
        print("="*80)
        
        # í† í° ìˆ˜ ê³„ì‚°
        print("\n[í† í° ìˆ˜ ë¶„ì„]")
        print("-" * 80)
        
        # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ê°€ ì…ë ¥ë°›ëŠ” ë°ì´í„° (ToolMessage ë‚´ ì „ì²´ ë°ì´í„°)
        messages = result_state.get("messages", [])
        tool_messages_data_tokens = 0
        tool_messages_full_tokens = 0  # ToolMessage ì „ì²´ (data + notes + sources í¬í•¨)
        input_messages_tokens = 0  # HumanMessage, AIMessage ë“± ì…ë ¥ ë©”ì‹œì§€
        
        for msg in messages:
            msg_type = type(msg).__name__
            content = getattr(msg, "content", "")
            
            # ì…ë ¥ ë©”ì‹œì§€ (HumanMessage, AIMessage)
            if msg_type in ["HumanMessage", "AIMessage"]:
                if content:
                    input_messages_tokens += count_tokens(str(content))
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tc in msg.tool_calls:
                        input_messages_tokens += count_tokens(json.dumps(tc, ensure_ascii=False))
            
            # ToolMessageì˜ contentì—ëŠ” ì „ì²´ ë°ì´í„°ê°€ í¬í•¨ë¨ (ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ê°€ ì‹¤ì œë¡œ ë°›ëŠ” ë°ì´í„°)
            if msg_type == "ToolMessage":
                tool_content = getattr(msg, "content", "")
                if tool_content:
                    tool_messages_full_tokens += count_tokens(tool_content)  # ToolMessage ì „ì²´
                    try:
                        tool_data = json.loads(tool_content)
                        if isinstance(tool_data, dict) and "data" in tool_data:
                            # ì „ì²´ ë°ì´í„° ë°°ì—´ì˜ í† í° ìˆ˜ ê³„ì‚°
                            data_array = tool_data.get("data", [])
                            if data_array:
                                data_json = json.dumps(data_array, ensure_ascii=False)
                                tool_messages_data_tokens += count_tokens(data_json)
                    except:
                        pass
        
        # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ê°€ ì¶œë ¥í•˜ëŠ” ë°ì´í„°
        research_notes = result_state.get("research_notes", "")
        notes_tokens = count_tokens(research_notes)
        
        research_sources = result_state.get("research_sources", [])
        sources_text = json.dumps(research_sources, ensure_ascii=False)
        sources_tokens = count_tokens(sources_text)
        
        research_payload = result_state.get("research_payload", [])
        payload_text = json.dumps(research_payload, ensure_ascii=False)
        payload_tokens = count_tokens(payload_text)
        
        # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ì˜ ìµœì¢… ì¶œë ¥ (research_notes + research_sources)
        research_output_tokens = notes_tokens + sources_tokens
        
        # ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•œ ì „ì²´ í† í° (ì…ë ¥ + ì¶œë ¥)
        research_total_tokens = input_messages_tokens + tool_messages_full_tokens + research_output_tokens
        
        print("=" * 80)
        print("ğŸ“¥ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì…ë ¥ ë°ì´í„°")
        print("=" * 80)
        print(f"   - ì…ë ¥ ë©”ì‹œì§€ (HumanMessage, AIMessage): {input_messages_tokens:,} í† í°")
        print(f"   - ToolMessage ì „ì²´ (notes + sources + data): {tool_messages_full_tokens:,} í† í°")
        print(f"     â””â”€ ê·¸ ì¤‘ ë°ì´í„° ë°°ì—´ (50ê°œ ì „ì²´ + DESCRIPTION): {tool_messages_data_tokens:,} í† í°")
        print(f"   ğŸ“Š ì…ë ¥ ì´í•©: {input_messages_tokens + tool_messages_full_tokens:,} í† í°")
        
        print("\n" + "=" * 80)
        print("ğŸ“¤ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì¶œë ¥ ë°ì´í„°")
        print("=" * 80)
        print(f"   - ì—°êµ¬ ë©”ëª¨ (research_notes): {notes_tokens:,} í† í°")
        print(f"   - ì°¸ê³  ì¶œì²˜ (research_sources): {sources_tokens:,} í† í°")
        print(f"   - ë°ì´í„° í˜ì´ë¡œë“œ (research_payload): {payload_tokens:,} í† í°")
        print(f"   ğŸ“Š ì¶œë ¥ ì´í•©: {research_output_tokens:,} í† í°")
        
        print("\n" + "=" * 80)
        print("ğŸ“Š ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì „ì²´ ì²˜ë¦¬ í† í° ìˆ˜")
        print("=" * 80)
        print(f"   ì…ë ¥: {input_messages_tokens + tool_messages_full_tokens:,} í† í°")
        print(f"   ì¶œë ¥: {research_output_tokens:,} í† í°")
        print(f"   ğŸ“Š ì´í•©: {research_total_tokens:,} í† í°")
        print(f"\n   âš ï¸  ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ëŠ” ToolMessageë¡œ ì „ì²´ 50ê°œ ë°ì´í„°(+DESCRIPTION)ë¥¼ ë°›ì•„ì„œ ìš”ì•½í•©ë‹ˆë‹¤.")
        print(f"   âš ï¸  ë¶„ì„ ì—ì´ì „íŠ¸ëŠ” research_notes(ìš”ì•½)ì™€ research_sources(URL ëª©ë¡)ë§Œ ë°›ìŠµë‹ˆë‹¤.")
        
        print("\n[ì—°êµ¬ ë©”ëª¨]")
        print("-" * 80)
        print(result_state.get("research_notes", "ì—†ìŒ"))
        
        print("\n[ì°¸ê³  ì¶œì²˜]")
        print("-" * 80)
        sources = result_state.get("research_sources", [])
        if sources:
            for i, source in enumerate(sources[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                print(f"{i}. {source}")
            if len(sources) > 10:
                print(f"... ì™¸ {len(sources) - 10}ê°œ")
        else:
            print("ì—†ìŒ")
        
        print("\n[ìˆ˜ì§‘ëœ ë°ì´í„° í˜ì´ë¡œë“œ]")
        print("-" * 80)
        print("âš ï¸  ì£¼ì˜: ì´ ë°ì´í„°ëŠ” ë””ë²„ê¹…ìš©ìœ¼ë¡œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
        print("âš ï¸  ì‹¤ì œ ë¶„ì„ ì—ì´ì „íŠ¸ëŠ” research_notes(í…ìŠ¤íŠ¸ ìš”ì•½)ì™€ research_sources(URL ëª©ë¡)ë§Œ ë°›ìŠµë‹ˆë‹¤.")
        print("âš ï¸  research_payloadì˜ ìƒ˜í”Œ ë°ì´í„°ëŠ” ìƒíƒœì— ì €ì¥ë˜ì§€ë§Œ ë¶„ì„ ì—ì´ì „íŠ¸ì—ê²ŒëŠ” ì „ë‹¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n")
        payloads = result_state.get("research_payload", [])
        if payloads:
            for i, payload in enumerate(payloads, 1):
                print(f"\n{i}. ë„êµ¬: {payload.get('tool', 'N/A')}")
                print(f"   ì¸ì: {json.dumps(payload.get('args', {}), ensure_ascii=False, indent=2)}")
                print(f"   ë°ì´í„° ê°œìˆ˜: {payload.get('count', 0)}")
                print(f"   âš ï¸  ì‹¤ì œ ìˆ˜ì§‘ëœ ë°ì´í„°: {payload.get('count', 0)}ê°œ ì „ì²´")
                print(f"   âš ï¸  ìƒ˜í”Œ ë°ì´í„° (research_payloadì— ì €ì¥ëœ ê²ƒ): ì²« 5ê°œë§Œ (ì•„ë˜ëŠ” ì²« 1ê°œ)")
                if payload.get('sample'):
                    print(f"   ìƒ˜í”Œ ë°ì´í„° (ì²« 1ê°œ):")
                    print(json.dumps(payload['sample'][0], ensure_ascii=False, indent=4))
        else:
            print("ì—†ìŒ")
        
        print("\n[ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬]")
        print("-" * 80)
        messages = result_state.get("messages", [])
        for i, msg in enumerate(messages, 1):
            msg_type = type(msg).__name__
            content = getattr(msg, "content", "")
            print(f"\n{i}. [{msg_type}]")
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                print(f"   ë„êµ¬ í˜¸ì¶œ:")
                for tc in msg.tool_calls:
                    print(f"     - {tc.get('name', 'N/A')}: {json.dumps(tc.get('args', {}), ensure_ascii=False)}")
            if content:
                # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì¶œë ¥
                content_str = str(content)[:500]
                if len(str(content)) > 500:
                    content_str += "... (ìƒëµ)"
                print(f"   ë‚´ìš©: {content_str}")
        
        print("\n" + "="*80)
        print("âœ… ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
        print("="*80 + "\n")
        
    except Exception as e:
        print("\n" + "="*80)
        print("âŒ ì˜¤ë¥˜ ë°œìƒ")
        print("="*80)
        print(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        print("="*80 + "\n")


if __name__ == "__main__":
    main()
